[Call for submissions](./call.md)

## Description

A long-standing objective of AI research has been to discover theories of reasoning that are general: accommodating various forms of knowledge and applicable across a diversity of domains. The last two decades have brought steady advances toward this goal, notably in the form of mature theories of probabilistic and causal inference, and in the explosion of reasoning methods built upon the deep learning revolution. However, these advances have only further exposed gaps in both our basic understanding of reasoning and in limitations in the flexibility and composability of automated reasoning technologies.  This workshop aims to reinvigorate work on the grand challenge of developing a computational foundation for reasoning in minds, brains, and machines.


## Topics
Cognitive science of formal and intuitive reasoning

Plausible cognitive neuroscientific foundations for general reasoning systems 

Machine learning approaches to theorem proving and deductive reasoning

The semantics of natural language reasoning with large language models

Design and implementation of probabilistic & differentiable programming languages

Advances in formal languages and implementations for formalizing mathematics

Algorithms and representations for causal and counterfactual reasoning

Causal queries beyond counterfactuals, e.g. actual causality & causal explanation

Insights from algorithms and representations in modern SAT and SMT solvers

Unifying semantic and algorithmic frameworks for distinct forms of reasoning

## Goals: 

Expose forms of reasoning that are novel/underexplored within the ML community, ultimately leading to their formalization and implementation in software

Develop a shared conceptual and mathematical vocabulary between researchers in cognitive (neuro) science, Bayesian and causal inference, machine learning, logic, programming languages, and automated reasoning

Advance novel knowledge representations and inference algorithms that are qualitatively more general and expressive than SoA, even if currently less efficient

Predict what lies beyond the current languages and algorithms for reasoning, and pinpoint algorithmic and conceptual roadblocks that must be overcome

## Planned activities
The workshop will consist of several types of sessions, broken up by 15 min coffee breaks. Discussion will be encouraged at all sessions, and there will be an option for contributed talks and posters. Invited talks will be 25 min followed by 10 min breakout discussion at tables and 10 min full group Q&A with the speaker. Panel discussions will consist of three invited panelists each giving a 15 min talk, then a discussion moderated by an organizer. Lunch will be provided, with suggestions for lunch discussion, followed by a short recap. Contributed talks will be 15 min each and a poster session will be 1hr.  Both will be selected by organizers from 1 paragraph abstract submissions. These times may be adapted to accommodate speakers who confirm later.

### Rough timeline: 

9am-9:45am: Invited talk on new reasoning problems and modes of reasoning. 

10am-11:15am: Panel, “Reasoning in brains vs machines”

11:30am-12:45pm: Invited talk on the cognitive science of reasoning.

12:45pm-1:45pm: Lunch discussion

1:45pm-3pm: Panel, “New computational technologies for reasoning”

3-3:45pm: Invited talk on the future of automated reasoning

4pm-5pm: Contributed talks

5pm-6pm: Poster session/social

## Organizers

### Nada Amin 
Nada Amin is an assistant professor of computer science at Harvard SEAS. Previously, she was a University Lecturer in Programming Languages at the University of Cambridge, and a member of the team behind the Scala programming language at EPFL. She is broadly interested in programming languages, and the intersection of programming languages and artificial intelligence. She has co-organized the Scala, Scheme, miniKanren and TyDe (Type-driven Development) workshops, and has served on the program committee of POPL, FLOPS, OOPSLA, UAI among others.

### Eli Bingham
Eli is a Machine Learning Fellow at the Broad Institute of MIT and Harvard's Data Sciences Platform, where he develops machine learning methods and software for biomedical research applications, and was previously a senior research scientist at Uber AI Labs. His research at the intersection of programming languages and AI focuses on developing general methods for approximate Bayesian inference suited for new and previously inaccessible problems, and on democratization of those methods through the Pyro probabilistic programming language, of which he is a co-creator and core developer. He has served as a program committee member of scientific workshops including HOPE and LAFI, and has also organized and led a number of public and private workshops and tutorials for current and prospective Pyro users.

### Nan Rosemary Ke
Rosemary is a research scientist at Deepmind. Previously, she was a PhD student at Mila, advised by Yoshua Bengio and Chris Pal. Her research centers around developing novel machine learning algorithms that can generalize well to changing environments. Her research focuses on two key ingredients: credit assignment and causal learning. These two ingredients flow into and reinforce each other: appropriate credit assignment can help a model refine itself only at relevant causal variables, while a model that comprehends causality sufficiently well can reason about the connections between causal variables and the effect of intervening on them. She has co-organized a conference, 6 workshops and 3 challenges. These are the conference on causal learning and reasoning (CLeaR) 2022, the “inductive biases, invariances and generalization in reinforcement learning” workshop at ICML 2020, “causal learning for decision making” workshop at ICLR2020, “efficient credit assignment workshop” at ICML 2018, “reproducibility in machine learning” at ICML 2017, ICML 2018 and ICLR 2019), the “Real robot challenge” at NeurIPS 2021 and the ICLR reproducibility challenge at ICLR 2018 and ICLR 2019. 

### John Krakauer 
Dr. John Krakauer is John C. Malone Professor, Professor of Neurology, Neuroscience, and Physical Medicine and Rehabilitation, Director of the Brain, Learning, Animation, and Movement Lab at The Johns Hopkins University School of Medicine, and External Professor at the Santa Fe Institute. His areas of research interest include experimental and computational studies of motor control and motor learning in humans, motor recovery and rehabilitation after stroke, and philosophy of mind. He has organized numerous workshops and scientific meetings, recently including The Learning Salon.

### Armando Solar Lezama 
Armando Solar-Lezama is a Professor in the Department of Electrical Engineering and Computer science and associate director of the Computer Science and Artificial Intelligence Lab at MIT. His background is in programming languages, where he is best known for his seminal work on program synthesis. More recently, he has been working at the intersection of programming languages and machine learning, exploring learning techniques that combine the formal guarantees of program synthesis with the expressiveness of traditional machine learning.  He has co-organized a number of workshops including the Workshop on Computer Assisted Programming (CAP) at NeurIPS 2020 and the workshop on Machine Learning and Programming Languages (MAPL) at PLDI 2019. 

### Emily Mackevicius
Emily Mackevicius is currently a postdoctoral neuroscientist at Columbia University in the Aronov lab. Previously, she completed her Ph.D. in neuroscience at MIT in the Fee lab. Her research investigates how the brain learns new information in the context of prior knowledge.  Her work involves both experiments (recording neurons in birds performing naturalistic memory behaviors) and theory/computation (modeling how neural circuits self-organize, and developing a sequence-detection method, seqNMF).  She has been involved in organizing a variety of scientific meetings, including founding an ongoing tutorial series on computational topics at MIT's Brain and Cognitive Sciences Department, and TAing Woods Hole summer courses ("Methods in Computational Neuroscience", and "Brains, Minds, and Machines"). 

### Talia Ringer
Talia Ringer is an assistant professor at the University of Illinois at Urbana-Champaign. Her work focuses on tools that make it easier to develop and maintain systems verified using proof assistants. Toward that end, she loves to use the whole toolbox—everything from dependent type theory to program transformations to neural proof synthesis—all in service of real humans verifying real systems. Prior to Illinois, she earned her PhD in 2021 from the University of Washington. She also has experience in industry. She has served the community in many capacities, including as founder and chair of the SIGPLAN long-term mentoring committee (SIGPLAN-M), co-chair of PLMW at ICFP 2020, hybridization co-chair of SPLASH 2021, co-organizer of the Coq Workshop 2022, and program committee member for PLDI, ITP, TYPES, CAV, CoqPL, HATRA, and AIPLANS.

### Zenna Tavares
Zenna Tavares is the inaugural Innovation Scholar in Columbia University’s Zuckerman Mind Brain Behavior Institute, and Associate Research Scientist in the Data Science Institute. Zenna’s research aims to understand how humans reason, that is, how they come to derive knowledge from observing and interacting with the world. He also constructs computational and statistical tools that help advance his work on causal reasoning, probabilistic programming, and other areas. Prior to Columbia University, he was at MIT, where he received a PhD in Cognitive Science and Statistics and was a Postdoctoral Research researcher in the Computer Science Artificial Intelligence Lab (CSAIL). Zenna has co-organized a number of workshops, including DBAI at Neurips 2021, and OOD Generalization at Neurips 2021, and served on the program committee for UAI, ICML, Neurips, ICLR, and LAFI (POPL).
